{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import signal\n",
    "import multiprocessing\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from datetime import datetime\n",
    "\n",
    "DATADIR = \"datasets/\"\n",
    "LOGDIR = \"logs/\"\n",
    "MODELDIR = \"models/\"\n",
    "\n",
    "IMG_WIDTH = 96\n",
    "IMG_HEIGHT = 96\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PCAM, PCAM_INFO = tfds.load(\"patch_camelyon\", with_info=True, as_supervised=True)\n",
    "\n",
    "early_stop_cb = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0,\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "def sample_preprocess(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    label = tf.one_hot(label, 2, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "TRAINING_DATA = PCAM[\"train\"].map(sample_preprocess, num_parallel_calls=tf.data.AUTOTUNE).shuffle(1024).repeat().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "VALIDATION_DATA = PCAM[\"validation\"].map(samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cordless-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIAL TRAINING PARAMETERS ###\n",
    "CONV_LAYERS = [2, 3, 4]\n",
    "LAYER_SIZES = [32, 64, 128]\n",
    "DENSE_LAYERS = [1, 2, 3]\n",
    "trained_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params):\n",
    "    dense_layer = params[\"dense_layer\"]\n",
    "    layer_size = params[\"layer_size\"]\n",
    "    conv_layer = params[\"conv_layer\"]\n",
    "    NAME = \"{} - CONV-{} NODES-{} DENSE-{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M%S\"), conv_layer, layer_size, dense_layer)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOGDIR + NAME)\n",
    "            \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(layer_size, (3,3), input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "    iter_size = layer_size * 2\n",
    "    for i in range(conv_layer - 1):\n",
    "        model.add(Conv2D(iter_size, (3,3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        iter_size = iter_size * 2\n",
    "                \n",
    "    model.add(Flatten())\n",
    "    dense_layer_size = 512\n",
    "    for i in range(dense_layer):\n",
    "        model.add(Dense(dense_layer_size))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        dense_layer_size = dense_layer_size / 2\n",
    "    # Final categorisation\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    sgd_opt = SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=True)\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                         optimizer=sgd_opt,\n",
    "                         metrics=[\"accuracy\"])\n",
    "    print(\"Fitting data for {}\".format(NAME))\n",
    "    model.fit(TRAINING_DATA,\n",
    "                     epochs=30,\n",
    "                     validation_data=VALIDATION_DATA,\n",
    "                     steps_per_epoch=4096,\n",
    "                     validation_steps=256,\n",
    "                     callbacks=[tensorboard_callback, early_stop_cb])\n",
    "    \n",
    "    model.save(MODELDIR + NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BUILD COMBINATION OF MODELS FROM PARAMETERS ###\n",
    "for dense_layer in DENSE_LAYERS:\n",
    "    for layer_size in LAYER_SIZES:\n",
    "        for conv_layer in CONV_LAYERS:\n",
    "            trained_models.append({\"dense_layer\": dense_layer, \"layer_size\": layer_size, \"conv_layer\": conv_layer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MANUAL BUILDING OF MODELS ###\n",
    "trained_models = [{'conv_layer': 4,\n",
    "                 'dense_layer': 3,\n",
    "                 'layer_size': 64}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START TRAINING OF MODELS ###\n",
    "for m in trained_models:\n",
    "    train_model(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
